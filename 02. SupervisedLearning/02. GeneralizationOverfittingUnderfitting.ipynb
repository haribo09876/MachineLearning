{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generalization (일반화) / Overfitting (과대적합) / Underfitting (과소적합)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization (일반화)\n",
    "- 지도학습에서는 훈련 데이터로 학습한 모델이 훈련 데이터와 특성이 같다면 처음 보는 새로운 데이터가 주어져도 정확히 예측할 것으로 기대\n",
    "- 모델이 처음 보는 데이터에 대해 정확하게 예측할 수 있으면 이를 훈련 테스트 세트로 일반화 되었다고 표현\n",
    "- 모델을 만들 때는 가능한 한 정확하게 일반화되도록 해야 함\n",
    "\n",
    "### Overfitting (과대적합)\n",
    "- 가진 정보를 모두 사용해서 너무 복잡한 모델을 만드는 것\n",
    "- 모델이 훈련 세트의 각 샘플에 너무 가깝게 맞춰져서 새로운 데이터에 일반화되기 어려울 때 일어남\n",
    "\n",
    "### Underfitting (과소적합)\n",
    "- 너무 간단한 모델이 선택되는 것. 모델이 너무 간단하면, 데이터의 면면과 다양성을 잡아내지 못할 것이고, 훈련 세트에도 잘 맞지 않을 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 모델 복잡도와 데이터셋 크기의 관계\n",
    "- 모델의 복잡도는 훈련 데이터셋에 담긴 입력 데이터의 다양성과 관련이 깊음\n",
    "- 데이터셋에 다양한 데이터 포인트가 많을수록 과대적합 없이 더 복잡한 모델을 만들 수 있음\n",
    "- 보통 데이터 포인트를 더 많이 모으는 것이 다양성을 키워주므로 큰 데이터셋은 더 복잡한 모델을 만들 수 있게 함\n",
    "- 그러나 같은 데이터 포인트를 중복하거나 매우 비슷한 데이터를 모으는 것은 도움이 되지 않음\n",
    "- 데이터를 더 많이 수집하고 적절하게 더 복잡한 모델을 만들면 지도 학습 문제에서 종종 놀라운 결과를 얻을 수 있음\n",
    "- 모델을 변경하거나 조정하는 것보다 이득일 수 있으므로 데이터양의 중요성을 과소평가하지 말것. 따라서 실제 환경에서는 데이터를 얼마나 많이 모을지 결정해야 함"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
