{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지도 학습과 비지도 학습의 중요한 알고리즘들을 적용하여 다양한 모신러닝 문제를 해결하는 방법을 배웠음\n",
    "- 머신러닝의 무궁무진한 세계로 떠나기 전에 마지막 조언과 함께 몇 가지 참고 자료를 소개하고 실력 있는 머신러닝 기술자와 데이터 과학자가 되는 길을 제시했음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 머신러닝 문제 접근 방법\n",
    "- 이 책에서 소개한 방법들을 모두 익혔으니 당장 데이터 관련 문제를 해결하려고 맘에 드는 알고리즘을 적용하고 싶을지 모름\n",
    "- 하지만 일반적으로 분석을 시작하는 좋은 방식은 아님\n",
    "- 전체 데이터 분석과 의사 결정 과정에서 머신러닝 알고리즘이 차지하는 부분은 보통 작음\n",
    "- 머신러닝을 효과적으로 사용하려면 한 걸음 뒤로 물러나 넓은 시각으로 문제를 바라봐야 함\n",
    "- 먼저 답을 얻고자 하는 질문이 어떤 종류인지 생각\n",
    "- 탐색적 분석으로 데이터에 뭔가 흥미로운 것이 있는지 찾고 싶은가? 마음속에 이미 정한 목표가 있나? 부정거래 탐지나 영화 추천, 알려지지 않은 행성을 탐색하는 것처럼 어떤 목적을 가지고 시작하는 경우가 많음\n",
    "- 목표가 있다면 시스템을 구축하기 전에 먼저 성공을 어떻게 정의하고 측정할지, 최종 솔루션이 비즈니스와 연구의 목표에 어떤 영향을 줄지 생각해봐야 함\n",
    "- 예를 들어 부정거래 탐지가 목적이라고 가정하는 경우, 다음과 같은 질문이 가능함\n",
    "- 1) 부정거래 예측이 실제로 작동하는지 어떻게 측정할까?\n",
    "- 2) 알고리즘을 평가하기에 알맞은 데이터를 가지고 있는가?\n",
    "- 3) 성공적으로 구축했다면 이 솔루션이 비즈니스에 어떤 영향을 주는가?\n",
    "- 5장에서 보았듯이 이익 증가율이나 손실 감소율 같은 비즈니스 척도를 직접 이용해 알고리즘 성능을 재는 게 가장 좋음\n",
    "- 하지만 이런 방식을 사용하기 어려울 때가 많음\n",
    "- 간단하게 \"완벽한 모델이란 무엇인가?\"라는 질문의 답을 찾으면 됨\n",
    "- 모든 부정 거래를 완벽하게 감지했을 때 회사가 한 달에 100달러를 아낄 수 있다면 알고리즘을 개발하려는 시도조차 할 필요가 없음\n",
    "- 반면에 모델이 한 달에 수 만 달러를 아낄 수 있다면 이 문제는 들여다볼 가치가 있음\n",
    "- 해결해야 할 문제를 정의했고 솔루션이 프로젝트에 미칠 영향과 성공을 평가할 올바른 방법을 알고 있다고 가정\n",
    "- 다음 단계는 데이터를 모으고 작동하는  프로토타입을 만드는 일임\n",
    "- 선택할 수 있는 많은 모델을 다루었고 어떻게 평가하고 튜닝하는지 설명했음\n",
    "- 하지만 모델을 적용할 때 기억해야 할 것은 모델이 커다란 데이터 과학 워크플로의 일부라는 것\n",
    "- 모델 구축은 새로운 데이터를 모으고, 정제하고, 만들고, 평가하는 순환 사이클의 한 부분임\n",
    "- 모델이 만든 오류를 분석하면 빠진 데이터나 추가로 수집할 데이터, 더 효과적인 모델을 위해 어떻게 작업을 재구성할지에 대한 정보를 많이 얻을 수 있음\n",
    "- 더 많은 데이터를 수직하거나 작업 흐름을 바꾸는 것이 매개변수 튜닝을 위해 끝없이 그리드 서치를 돌리는 것보다 훨씬 이득일 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. 의사 결정 참여\n",
    "- 의사 결정에 사람이 개입해야 할지도 고려해야 함\n",
    "- 어떤 작업은 (자율 주행 자동차의 보행자 탐지 같은) 즉각적인 결정이 필요함\n",
    "- 즉각 응답하지 않아도 될 때는 불확실한 결정을 사람이 확인하게 할 수 있음\n",
    "- 예를 들어 의료 애플리케이션은 정확도가 아주 높아야 해서 머신러닝 알고리즘 단독으로는 달성하기가 불가능함\n",
    "- 알고리즘이 90%, 50% 또는 10%라도 자동으로 의사 결정을 할 수 있다면 응답 시간을 빠르게 하고 비용을 줄여줌\n",
    "- 대부분의 애플리케이션은 알고리즘이 의사 결정을 할 수 있는 단순한 경우이고 사람이 참여해야 하는 복잡한 경우는 비교적 드뭄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 프로토타입에서 제품까지\n",
    "- 이 책에서 다룬 도구들은 여러 머신러닝 애플리케이션에 잘 맞으며 분석과 프로토타입을 빠르게 수행해줌\n",
    "- 다국적 은행과 글로벌 소셜 미디어 같은 매우 큰 기관도 제품에 파이썬과 scikit-learn을 사용\n",
    "- 하지만 복잡한 인프라를 가진 회사는 파이썬을 자사 시스템에 통합시키기 어려울 때가 있음\n",
    "- 이는 반드시 문제가 되지는 않음\n",
    "- 많은 회사에서 데이터 분석팀은 파이썬과 R을 사용해 빠르게 아이디어를 시험하고 제품팀은 안정적이고 큰 규모의 시스템을 위해 Go, Scala, C++, Java 같은 언어를 사용\n",
    "- 데이터 분석을 실제 서비스에 반영하려면 다양한 요구사항이 발생하므로 이런 작업들을 처리하려면 보통은 여러 언어를 사용해야 함\n",
    "- 분석팀에서 찾은 솔루션을 고성능 언어를 사용하여 더 큰 프레임워크 안에서 재구현하는 것이 비교적 일반적임\n",
    "- 이 방법이 전체 라이브러리나 프로그래밍 언어를 내장시키고 포맷이 다른 데이터를 이리저리 변환하는 것보다 쉬움\n",
    "- 제품 시스템에서 scikit-learn을 사용할 수 있는지와 상관없이 제품 시스템에는 일회용 분석 스크립트와는 다른 요구사항이 있다는 것을 꼭 유념해야 함\n",
    "- 한 알고리즘이 큰 시스템에 정착되려면 신뢰성, 예측 가능성, 실행환경, 메모리 요구사항 같은 소프트웨어 공학적인 측면이 필요함\n",
    "- 이런 환경에서 잘 작동하는 머신러닝 시스템을 구축하는 데 필요한 핵심 요소는 단순함임\n",
    "- 데이터 처리와 예측 파이프라인의 각 부분을 자세히 조사하고 각 단계가 복잡도를 얼마나 키우는지, 각 구성요소가 데이터나 컴퓨터 인프라의 변화에 얼마나 견고한지, 각 단계가 복잡도를 감내한 만큼 유익한지 스스로에게 물어봐야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 제품 시스템 테스트\n",
    "- 이 책에서 사전에 수집한 테스트 세트를 기초로 하여 알고리즘이 만든 예측을 평가하는 방법을 다뤘음\n",
    "- 이를 오프라인 평가(Offline Evaluation)라고 함\n",
    "- 사용자에게 노출되는 머신러닝 시스템이라면 이는 알고리즘을 평가하는 첫 단계일 뿐임\n",
    "- 다음 단계는 전체 시스템에 알고리즘이 적용된 이후에 평가하는 온라인 테스트(Online Test) 혹은 라이브 테스트(Live Test)임\n",
    "- 웹사이트에 보여지는 추천이나 검색 결과를 변경하면 사용자의 행동을 크게 바꾸거나 예상치 못한 결과를 얻을 수 있음\n",
    "- 이런 돌발 상황을 방지하기 위해 대부분 사용자 서비스가 일종의 블라인드 테스트인 A/B 테스트를 사용함\n",
    "- A/B 테스트에서는 사용자 중 일부가 자신도 모르게 알고리즘 A를 사용한 웹사이트나 서비스를 이용하게 됨\n",
    "- 반면 나머지 사용자는 알고리즘 B에 노출됨\n",
    "- 두 그룹에 대해 적절한 성공 지표를 일정 기간 선택함\n",
    "- A/B 테스트를 사용하면 실전에서 알고리즘을 평가해볼 수 있고 사용자들에게 모델이 노출됐을 때 예상치 못한 결과를 발견할 수도 있음\n",
    "- 보통 A가 새 모델이고 B는 기존 시스템\n",
    "- A/B 테스트 외에도 밴디트 알고리즘(Bandit Algorithms)같이 온라인 테스트를 위한 정교한 방법들이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 나만의 추정기 만들기\n",
    "- 이 책에서 여러 분야에 적용할 수 있는 다양한 scikit-learn의 도구와 알고리즘을 소개했음\n",
    "- scikit-learn에 구현되지 않은 방식으로 데이터를 처리해야 할 때가 있음\n",
    "- scikit-learn 모델이나 파이프라인에 데이터를 주입하기 전에 전처리하는 것으로 충분할지도 모름\n",
    "- 하지만 데이터의 통계를 사용하는 전처리라면 그리드 서치와 교차 검증을 사용해야 하므로 문제가 복잡해짐\n",
    "- 6장에서 모든 데이터 종속 처리는 교차 검증 루프 안에 넣어야 한다고 이야기 했음\n",
    "- 그럼 어떻게 자체적인 데이터 처리를 scikit-learn과 함께 쓸 수 있을까?\n",
    "- 간단한 방법으로 나만의 추정기를 만들면 됨\n",
    "- Pipeline, GridSearchCV와 cross_val_score를 사용할 수 있게끔 scikit-learn 인터페이스와 호환되는 추정기를 아주 쉽게 만들 수 있음\n",
    "- 변환기를 만드는 가장 쉬운 방법은 BaseEstimator와 TransformerMixin을 상속해서 다음과 같이 __init__, fit, transform 메서드를 구현하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MyTransformer(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self, first_parameter=1, second_parameter=2):\n",
    "    # __init__ 메서드에 필요한 모든 매개변수를 나열\n",
    "    self.first_parameter = 1\n",
    "    self.second_parameter = 2\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    # fit 메서드는 X와 y 매개변수만을 갖음\n",
    "    # 비지도 학습 모델이더라도 y 매개변수를 받도록 해야 함\n",
    "\n",
    "    # 모델 학습 시작\n",
    "    print(\"모델 학습을 시작합니다\")\n",
    "    # 객체 자신인 self를 반환\n",
    "    return self\n",
    "  \n",
    "  def transform(self, X):\n",
    "    # transform 메서드는 X 매개변수만을 받음\n",
    "\n",
    "    # X를 변환\n",
    "    X_transformed = X + 1\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류와 회귀 모델을 만드는 것도 비슷해서 TransformerMixin 대신 ClassifierMixin이나 RegressorMixin을 상속하고, transform 대신 predict를 구현하면 됨\n",
    "- 앞의 코드에서 볼 수 있듯이 적은 양의 코드로 나만의 추정기를 만들 수 있어 대부분의 scikit-learn 사용자가 점차 자신만의 맞춤형 모델을 갖춰두고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 더 배울 것들\n",
    "- 이 책은 머신러닝의 입문서이고 실질적인 기술자가 되게 도와줄 것임\n",
    "- 여기서 더 나아가 머신러닝 기술을 향상시키고 더 깊게 공부하고 싶은 사람을 위해 책 몇 권과 전문적인 자료들을 추천함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 이론\n",
    "- 이 책에서는 복잡한 수학이나 컴퓨터 과학을 사용하지 않고 많이 사용하는 머신러닝 알고리즘들이 어떻게 작동하는지 직관적으로 설명했음\n",
    "- 하지만 많은 보델이 확률, 선형 대수, 최적화 등의 이론을 사용함\n",
    "- 알고리즘이 어떻게 구현되어 있는지 상세 내용을 모두 알 필요는 없지만 알고리즘 이면의 이론을 알아두면 더 나은 데이터 과학자가 될 수 있음\n",
    "- 머신러닝 이론을 설명하는 좋은 책이 많이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. 다른 머신러닝 프레임워크와 패키지\n",
    "- scikit-learn이 가장 인기 있는 머신러닝 패키지이고 파이썬이 가장 인기 있는 머신러닝 언어인 것은 사실이지만, 다른 선택도 많이 있음\n",
    "- 요구사항에 따라 파이썬과 scikit-learn이 상황에 맞는 최선의 도구가 아닐 수 있음\n",
    "- 파이썬이 모델을 만들고 평가하는 데 좋은 도구지만 대규모 웹 서비스나 애플리케이션은 Java나 C++로 만들어진 경우가 많아 모델을 실전에 배치하려면 이런 시스템과 통합해야 함\n",
    "- scikit-learn 말고 다른 것을 찾아야 하는 또 다른 상황이라면 확률 모델링과 추론에 더 관심이 있을 때임\n",
    "- 이런 경우에는 statsmodels를 고려해볼 수 있음\n",
    "- 이 패키지는 조금 더 확률적 입장에서 인터페이스를 구축한 여러 선형 모델을 제공\n",
    "- 파이썬을 배우기 전이라면 데이터 과학자의 또 다른 공용어인 R을 고려해볼 수 있음\n",
    "- R은 통계 분석을 위해 특별히 설계된 언어이고, 훌륭한 시각화 기능과 (대부분 매우 전문적인) 많은 통계 모델 패키지를 활용할 수 있는 것으로 유명함\n",
    "- 머신러닝에서 유명한 또 다른 패키지로 명령어 인터페이스를 제공하고 C++로 작성된 vowpal wabbit이 있음(간단하게 vw라고 함)\n",
    "- vw는 특히 대량의 데이터셋과 스트리밍 데이터에 유용함\n",
    "- 클러스터에 머신러닝 알고리즘을 분산해서 실행하는 기능으로 가장 인기 있는 프레임워크로, Spark 분산 컴퓨터 환경에서 구축된 스칼라 분산 컴퓨터 환경에서 구축된 스칼라 라이브러리인 MLlib도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3. 랭킹, 추천 시스템과 그 외 다른 알고리즘\n",
    "- 이 책이 입문서이기 때문에 지도 학습인 분류와 회귀, 비지도 학습인 군집과 성분 분해 등 가장 일반적인 머신러닝 작업에 집중했음\n",
    "- 이 외에도 다양한 머신러닝 기술이 많은 애플리케이션에서 사용됨\n",
    "- 이 책에서 다루지 않았지만 특히 중요한 분야가 두 가지 있음\n",
    "- 1) 어떤 질문의 대답을 관련도 순으로 추출하는 랭킹임\n",
    "- 랭킹 시스템은 검색 엔진이 동작하는 원리\n",
    "- 검색어를 입력하면 관련도 순으로 순위가 매겨져 정렬된 목록을 얻음\n",
    "- 2) 사용자의 기호에 맞게 제안을 하는 추천 시스템\n",
    "- \"당신이 알 수도 있는 사람\", \"이 제품을 산 사람들이 구매한 제품\" 또는 \"당신을 위한 최고의 선택\"과 같은 추천 시스템이 있음\n",
    "- 넷플릭스 대회(http://www.netflixprize.com/)는 대규모 영화 선호도 데이터셋을 공개하고 가장 좋은 추천을 제공하는 팀에 상금을 주었음\n",
    "- 또 다른 일반적인 애플리케이션은 책 한 권을 통째로 할애할 만한 (ex) 주식 가격) 시계열 예측\n",
    "- 여기 언급한 것 외에도 수 많은 머신러닝 문제가 있음\n",
    "- 책이나 연구 논문, 온라인 커뮤니티 등을 참고할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-4. 확률 모델링, 추론, 확률적 프로그래밍\n",
    "- 대부분 머신러닝 패키지들이 사전에 하나의 특정 알고리즘을 적용하여 만든 머신러닝 모델을 제공\n",
    "- 그러나 실제 문제들은 독특한 구조를 가진 경우가 많고, 그 구조를 모델에 적절히 녹였을 때 예측을 더 잘할 수 있음\n",
    "- 종종 특정한 구조를 가진 문제는 확률 이론을 사요하여 표현할 수 있음\n",
    "- 이런 구조는 보통 예측하려는 환경을 수학적으로 모델링하여 만들어냄\n",
    "- 특정 구조의 문제를 잘 이해하려면 다음 예를 참고\n",
    "- 사람들에게 역사적인 장소를 안내하기 위해 야외 공간에서 아주 세밀하게 위치를 예측하는 모바일 애플리케이션을 만든다고 가정\n",
    "- 스마트폰에는 GPS, 가속도계, 나침반 같은 여러 센서가 있어 위치를 정밀하게 추적하느 ㄴ데 활용할 수 있음\n",
    "- 또 그 지역에 대한 자세한 지도도 가지고 있음\n",
    "- 이 문제는 매우 잘 구조화되어 있는 셈임\n",
    "- 지도로부터 관심 지역과 경로를 알 수 있음\n",
    "- GPS가 대략적인 위치를 알려주고 사용자 기기에 있는 가속도계와 나침반이 자세한 상대적 위치를 제공\n",
    "- 하지만 사용자의 위치를 예측하기 위해 이 모든 정보를 블랙박스 같은 머신러닝 시스템에 넣는 것은 좋은 생각이 아님\n",
    "- 우리가 알고 있는 작동 원리에 대한 정보를 잃게 되기 때문\n",
    "- 예를 들어 나침반과 가속도계가 사용자가 북쪽으로 향한다고 말하고 GPS는 사용자가 남쪽으로 간다고 알려주면, 우리는 아마도 GPS를 신뢰하지 않을 것임\n",
    "- 또 위치 예측 모델이 사용자가 벽을 통과해 걸어가고 있다고 알려주면 우리는 이를 잘못된 정보로 봄\n",
    "- 확률 모델을 사용하여 이런 상황을 나타낼 수 있으며 각 측정치를 얼마나 신뢰할 수 있을지, 머신러닝이나 확률적인 추론을 사용해서 사용자의 위치에 대한 최선의 예측을 이끌어낼 수 있음\n",
    "- 여러 요인이 함게 올바르게 작동하도록 모델과 상황을 잘 표현한다면 이런 맞춤형 모델을 직접 사용하여 예측을 계산하는 방법이 있음\n",
    "- 가장 일반적인 방법은 확률적 프로그래밍 언어이며 학습의 문제를 매우 우아하고 간결하게 표현하는 도구를 제공함\n",
    "- 인기 있는 확률적 프로그래밍 언어는 PyMC(파이썬에서 사용 가능)와 Stan(파이썬을 비롯해 몇몇 언어에서 사용할 수 있는 프레임워크)이 있음\n",
    "- 이런 패키지들을 사용하려면 확률 이론을 알아야 하지만 새로운 모델을 매우 간단하게 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-5. 신경망\n",
    "- 다른 신경망이 머신러닝 분야에서 빠르게 발전하는 영역이며 혁신과 새로운 애플리케이션이 매주 발표되고 있음\n",
    "- 알파고나 음성 인식의 성능 향상과 실시간 음성 번역 같은 머신러닝과 인공지능 분야의 최근 성과는 모두 신경망의 발전에 힘입었음\n",
    "- 이 분야의 발전이 너무 빨라서 현재 최고 성능의 결과가 금방 구식이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-6. 대규모 데이터셋으로 확장\n",
    "- 이 책에서는 우리가 다룰 데이터가 NumPy 배열이나 SciPy 희소 행렬로 RAM에 저장될 수 있는 크기라고 가정\n",
    "- 최신 서버들이 수백GB의 메모리를 가지고 있더라도 근본적으로 다룰 수 있는 데이터 크기에 한계가 있음\n",
    "- 모든 사람이 대용량의 장비를 구매하거나 클라우드 서버를 대여할 수 있는 것은 아님\n",
    "- 대부분 애플리케이션에서 머신러닝 시스템을 구축하는 데 필요한 데이터는 비교적 작지만 일부 소속의 머신러닝 데이터셋은 수백 기가바이트 이상임\n",
    "- 이런 경우에 메모리를 늘리거나 클라우드 서비스에서 장비를 늘리는 것이 해결책이 될 경우가 많음\n",
    "- 만약 테라바이트 정도의 데이터로 작업해야 하거나 적은 비용으로 대량의 데이터를 처리해야 한다면 기본적으로 두 가지 전략이 있음\n",
    "- 외부 메모리 학습(Out-of-Core)과 클러스터 병렬화(Parallelization Over a Cluster)임\n",
    "- 외부 메모리 학습은 메모리에 저장할 수 없는 데이터로 학습하는 것을 말하며, 학습이 하나의 컴퓨터 (심지어 하나의 프로세서)에서 수행됨\n",
    "- 데이터는 하드디스크 같은 저장소나 네트워크로부터 한 번에 샘플 하나씩 또는 메모리 용량에 맞는 크기의 덩어리로 읽어들임\n",
    "- 데이터가 처리되면 데이터로부터 학습된 것이 반영되도록 모델을 갱신함\n",
    "- 그런 다음 이 데이터 덩어리는 버리고 다음 덩어리를 읽음\n",
    "- scikit-learn의 일부 모델에서 외부 메모리 학습 기능을 구현해두었고 온라인 사용자 가이드에서 자세한 내용을 볼 수 있음\n",
    "- 외부 메모리 학습에서는 컴퓨터 한 대에서 모든 데이터를 처리해야 하므로 큰 데이터셋을 처리하려면 시간이 오래 걸림\n",
    "- 또 모든 머신러닝 알고리즘이 이 방식을 지원하는 것도 아님\n",
    "- 대규모 처리를 위한 다른 전략은 클러스터를 구성하는 여러 컴퓨터로 데이터를 분산해서 각 컴퓨터가 해당하는 데이터를 처리하는 것임\n",
    "- 일부 모델에서 처리 속도가 빨라지며 처리할 수 있는 데이터 크기는 클러스터 크기에 의해 제한됨\n",
    "- 하지만 이러한 연산 방식은 비교적 복잡한 인프라를 요구\n",
    "- 현재 가장 인기 있는 분산 컴퓨팅 플랫폼 중 하나는 하둡(Hadoop) 위에 구축된 스파크임\n",
    "- 스파크는 MLlib 패키지에 일부 머신러닝 기능을 포함하고 있음\n",
    "- 데이터가 이미 하둡 파일시스템에 저장되어 있거나 데이터 전처리를 위해 스파크를 쓰고 있다면 가장 손쉬운 방법임\n",
    "- 이런 인프라가 준비되어 있지 않은 경우 스파크 클러스터를 구축하고 통합하려면 많은 노력이 필요함\n",
    "- 앞서 이야기한 vw 패키지가 분산 기능을 조금 지원하므로 이런 경우 더 나은 대상이 될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-7. 실력 기르기\n",
    "- 이 책에서 다룬 주제에 대해 전문가가 되려면 연습밖에 방법이 없음\n",
    "- 주어진 과제와 데이터셋에 따라 특성 추출, 전처리, 시각화 그리고 모델 구축이 매우 달라짐\n",
    "- 이미 여러 종류의 데이터셋과 과제가 있다면 다행\n",
    "- 마음속에 정해진 문제가 없다면 머신러닝 대회가 좋은 출발점\n",
    "- 이런 대회에서는 주어진 문제와 데이터셋으로 최고의 예측을 만들려고 많은 팀이 경쟁함\n",
    "- 많은 회사와 비영리 기관, 대학이 이런 대회를 후원함\n",
    "- 가장 인기 있는 곳은 정기적으로 데이터 과학 대회를 열고 일부는 상금도 제공하는 Kaggle(https://www.kaggle.com/)이 있음\n",
    "- 캐글 포럼도 머신러닝 분야의 최신 도구와 기법에 관한 정보를 많이 얻을 수 있는 곳이고 여러 종류의 데이터셋을 구할 수 있음\n",
    "- 더 많은 데이터와 이와 연관된 과제는 OpenML 플랫폼(http://openml.org/)에서 찾을 수 있으며, 2만 개의 데이터셋과 5만 개의 관련 과제가 있음\n",
    "- 이런 데이터셋으로 작업하면 머신러닝 기술을 연습하는 데 아주 좋음\n",
    "- 대회의 단점이라 한다면, 최적화 지표를 특정하고 있으며 미리 가공된 고정 데이터셋을 사용하는 것임\n",
    "- 문제를 정의하고 데이터를 모으는 것도 실제 환경에서는 아주 중요하다는 사실을 유념해야 함\n",
    "- 문제를 잘 정의하는 것이 분류기의 정확도를 1% 높이는 것보다 훨씬 중요할지 모름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 마치며\n",
    "- 다양한 애플리케이션에서 머신러닝이 유용하고 실제로 쉽게 구현할 수 있다는 확신이 들었기를 바람\n",
    "- 데이터를 계속 파고들되 큰 그림을 놓치지 말아야 함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
