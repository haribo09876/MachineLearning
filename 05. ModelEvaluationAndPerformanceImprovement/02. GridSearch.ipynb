{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 그리드 서치 (GridSearch)\n",
    "- 앞에서 모델의 일반화 성능을 추정하는 법을 배웠고, 이제 다음 단계로 매개변수를 튜닝하여 일반화 성능을 개선하겠음\n",
    "- scikit-learn의 여러 알고리즘의 매개변수 설정에 대해 이야기했는데 매개변수를 조정하기 전에 그 매개변수의 의미를 이해하는 것이 중요함\n",
    "- 모델에서 중요한 매개변수의 (일반화 성능을 최대로 높여주는) 값을 찾는 일은 어려운 작업이지만, 모든 모델과 데이터셋에서 해야 하는 필수적인 일임\n",
    "- 많이 하는 작업이므로 scikit-learn에는 이를 위한 메서드가 준비되어 있음\n",
    "- 가장 널리 사용하는 방법은 그리드 서치로서 관심 있는 매개변수들을 대상으로 가능한 모든 조합을 시도해보는 것\n",
    "- SVC 파이썬 클래스에 구현된 RBF(Radial Basis Function) 커널 SVM을 사용\n",
    "- 커널의 폭에 해당하는 gamma와 규제 매개변수 C가 중요\n",
    "- 매개변수 C와 gamma에 0.001, 0.01, 0.1, 1, 10, 100 값을 적용해보겠음\n",
    "- C와 gamma의 설정값이 각각 6개씩이니 조합의 수는 총 36개\n",
    "- 모든 조합을 살펴보기 위해 SVM 매개변수 설정 테이블(그리드)을 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 간단한 그리드 서치\n",
    "- 두 매개변수 조합에 대해 분류기를 학습시키고 평가하는 간단한 그리드 서치를 for문을 사용해 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트의 크리: 112   테스트 세트의 크기: 38\n",
      "최고 점수: 0.97\n",
      "최적 매개변수: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# 간단한 그리드 서치 구현\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "print(\"훈련 세트의 크리: {}   테스트 세트의 크기: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "  for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    # 매개변수의 각 조합에 대해 SVC를 훈련시킴\n",
    "    svm = SVC(gamma=gamma, C=C)\n",
    "    svm.fit(X_train, y_train)\n",
    "    # 테스트 세트로 SVC를 평가\n",
    "    score = svm.score(X_test, y_test)\n",
    "    # 점수가 더 높으면 매개변수와 함께 기록\n",
    "    if score > best_score:\n",
    "      best_score = score\n",
    "      best_parameters = {\"C\": C, \"gamma\": gamma}\n",
    "\n",
    "print(\"최고 점수: {:.2f}\".format(best_score))\n",
    "print(\"최적 매개변수:\", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 매개변수 과대적합과 검증 세트\n",
    "- 앞의 결과를 보면 이 데이터셋에서 모델 정확도가 97%라고 보고할 수 있음\n",
    "- 하지만 이런 주장은 다음과 같은 이유로 매우 낙관적인 (혹은 잘못된) 것일 수 있음\n",
    "- 여러 가지 매개변수 값으로 많이 시도해보고 테스트 세트 정확도가 가장 높은 조합을 선택했음\n",
    "- 하지만 이 정확도는 새로운 데이터에까지 이어지지 않을 수 있음\n",
    "- 매개변수를 조정하기 위해 테스트 세트를 이미 사용했기 때문에 모델이 얼마나 좋은지 평가하는 데는 더 이상 사용할 수 없음\n",
    "- 맨 처음 데이터를 훈련 세트와 테스트 세트로 나눈 이유와 같음\n",
    "- 즉, 평가를 위해서는 모델을 만들 때 사용하지 않은 독립된 데이터셋이 필요\n",
    "- 데이터를 다시 나눠서 세 개의 세트로 만들어 이 문제를 해결할 수 있음\n",
    "- 훈련 세트로는 모델을 만들고, 검증 (또는 개발) 세트로는 모델의 매개변수를 선택하고, 테스트 세트로는 선택된 매개변수의 성능을 평가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
